# Awesome-Robotics

Welcome Everyone interested in robotics to Follow, to Suggest and to Push my project!ğŸ˜ˆ

| TitleğŸ“– | Conference & JournalğŸ“… | UnderstandingğŸ§  |QuestionğŸ¤”|
|:---------|:---------|:---------|:---------|
|Data Scaling Laws in Imitation Learning For Robotic Manipulation | ICLR 2025 & CoRL 2024 Workshop Best Paper | åœ¨æœºå™¨äººçš„å•ä»»åŠ¡ä¸Šï¼Œç ”ç©¶æ•°æ®è§„æ¨¡å’Œæ³›åŒ–æ€§çš„å…³ç³»ï¼Œç ”ç©¶å‘ç°æ•°æ®å¤šæ ·æ€§ï¼ˆåŒ…æ‹¬ç¯å¢ƒï¼Œç›®æ ‡ç‰©ä»¥åŠä¸¤è€…çš„æ ·æœ¬å¯¹ï¼‰å¯¹æå‡æœºå™¨äººæ¨¡å‹æ³›åŒ–æ€§ä¸Šå¤§è‡´ç¬¦åˆå¹‚å¾‹æ³•åˆ™ï¼Œæœ‰ç€å¾ˆé‡è¦çš„å½±å“ï¼Œç„¶è€Œå†…å®¹æè¿°æ•°æ®çš„è§„æ¨¡åœ¨è¶…è¿‡ä¸€å®šé˜ˆå€¼åå¯¹è®­ç»ƒä¸å†äº§ç”Ÿå½±å“ã€‚ |power-law relationshipåº”è¯¥å¹¿æ³›é€‚ç”¨äºRL,IRLç­‰é¢†åŸŸ;<br>æ­£å¦‚ä½œè€…æ‰€è®²çš„ç›®å‰é™äºsingle-taskï¼Œè¿˜æ²¡æœ‰å®Œæˆtask-generlizationï¼Œworkloadåº”è¯¥æ˜¯å¾ˆå·¨å¤§çš„ï¼Œå¦‚æœæ¨å¹¿åˆ°ç¨å¾®å¤æ‚ä¸€äº›çš„ä»»åŠ¡ï¼Œæ•°æ®å¤šæ ·æ€§åº”è¯¥æ˜¯å¾ˆåºå¤§çš„ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºç¯å¢ƒå’Œç›®æ ‡ç‰©ç­‰å› ç´ ;|
|Diffusing States and Matching Scores: A New Framework for Imitation Learning| ICLR 2025 | è¯¥ç¯‡æ–‡ç« æå‡ºäº†ä¸€ä¸ªæ–°çš„æ¨¡ä»¿å­¦ä¹ ç»“æ„ï¼Œé€šè¿‡ Diffusing States å’Œ Matching Scores æ¥å¢å¼ºçš„å­¦ä¹ æ•ˆæœã€‚||
|Adaptive Compliance Policy:Learning Approximate Compliance for Diffusion Guided Control| ICRA2025 |ç”±äºè¾ƒéš¾æ‰¾åˆ°å®Œç¾çš„åˆè§„æ€§ç­–ç•¥ï¼Œä½œè€…ä½¿ç”¨äº†è¿‘ä¼¼å­¦ä¹ æ¥å®Œæˆæœ€ä¼˜åˆè§„æ€§ç­–ç•¥çš„ä¼°è®¡ï¼Œç„¶åé€šè¿‡Qå‡½æ•°çš„å­¦ä¹ å’Œæ›´æ–°ï¼Œä¸æ–­è°ƒæ•´æ™ºèƒ½ä½“çš„è¡Œä¸ºï¼Œè¾¾åˆ°è¿‘ä¼¼æœ€ä¼˜åˆè§„çš„ç›®æ ‡||
|Look Before You Leap: Unveiling the Power of GPT-4V in Robotic Vision-Language Planning|arxiv2023| GPT4V to Robotic Vision-Language Planning|å¤§æ¨¡å‹çš„é¾™å·é£åˆ°äº†Robotic|
|Explaining and Harnessing Adversarial Examples|ICLR2015|é¦–æ¬¡æå‡ºäº†å¯¹æŠ—æ ·æœ¬é—®é¢˜ï¼Œå¹¶æå‡ºäº†é€šè¿‡å¯¹æŠ—è®­ç»ƒæ¥æé«˜æ¨¡å‹é²æ£’æ€§çš„æ€è·¯ï¼Œä»¥åŠæ¨¡å‹å¯ä»¥é€šè¿‡å¯¹æŠ—è®­ç»ƒï¼Œæ­£åˆ™åŒ–ï¼Œæ¢¯åº¦è£å‰ªå’Œæ•°æ®å¢å¼ºç­‰æ–¹æ³•æ¶ˆé™¤noiseçš„å½±å“|ç»å…¸ğŸ‘ï¼Œä¼Ÿå¤§æ— éœ€å¤šè¨€|
|Dream to Manipulate: Compositional World Models Empowering Robot Imitation Learning with Imagination|ICLR2025|æ–‡ç« çš„ä¸»è¦å·¥ä½œåŒ…æ‹¬ï¼š<br>ä½¿ç”¨é«˜æ–¯æ³¼æº… object-centric Gaussian Splatting ç”Ÿæˆ3Dç›®æ ‡ç‰©çš„è¡¨å¾; <br>ä»ç›¸æœºä¸­è·å–çš„è§†é¢‘å¤„ç†æˆå¸§åï¼Œè¿›è¡Œå›¾åƒåˆ†å‰²æ“ä½œ; <br>åˆ©ç”¨ç‰©ç†å¼•æ“PyBulleté¢„æµ‹æ¨¡å‹åœ¨çœŸå®ç¯å¢ƒä¸­çš„åç»­åŠ¨ä½œ; <br> å¯¹demonstrationè¿›è¡Œç­‰å˜å˜æ¢ï¼ˆEquivariant Transformationsï¼‰æ¥å¸®åŠ©æœºå™¨äººç”Ÿæˆimagination;  |è¯´å®è¯ï¼Œç»™æˆ‘çœ‹çš„äº‘é‡Œé›¾é‡Œçš„ã€‚æ–‡ç« åé¢çš„ç­‰å˜å˜æ¢ä¸å°±æ˜¯æ•°æ®å¢å¼ºå—ï¼Ÿç»è¿‡é«˜æ–¯æ³¼æº…ç”Ÿæˆçš„object representationå·²ç»æœ‰ç‚¹æŠ½è±¡äº†ï¼ŒçœŸçš„æœ‰ç”¨å—ï¼Ÿä½œè€…çš„motivationå¯ä»¥ç†è§£ï¼Œæ— éæ˜¯é’ˆå¯¹ILçš„çŸ­æ¿å»ä¸°å¯Œæ ·æœ¬é›†ã€‚|
|Diffusion Policy: Visuomotor Policy Learning via Action Diffusion| RSS2023|åœ¨è§†è§‰-è¿åŠ¨æ§åˆ¶ä»»åŠ¡ä¸­ï¼Œæ–‡ç« åŸºäºå¼ºåŒ–å­¦ä¹ çš„æ¡†æ¶ä½¿ç”¨æ‰©æ•£æ¨¡å‹ç”ŸæˆrobotåŠ¨ä½œåºåˆ—ï¼Œé€æ­¥ä¼˜åŒ–ç”Ÿæˆçš„åŠ¨ä½œè½¨è¿¹ä»¥è·å¾—è¿ç»­ã€å¹³æ»‘çš„åŠ¨ä½œè½¨è¿¹;å›¾åƒç‰¹å¾æå–å°±æ˜¯ä¼ ç»Ÿçš„CNN-Basedå’ŒTransformer-Basedï¼Œæ–‡ç« ä¸­ç»™å‡ºçš„performanceéƒ½æ˜¯åŸºäºTransformerçš„ï¼›æ­¤å¤–è¿˜ç»“åˆäº†æ§åˆ¶ç†è®ºæ¥å¸®åŠ©ç†è§£åœ¨ç®€å•ä»»åŠ¡ä¸‹çš„å±€é™æ€§ï¼›|Diffusionç»“åˆActionï¼Œè¿™ä¸ªæ–¹æ³•ç¡®å®æ˜¯è·å¾—è¿ç»­ä¸”å¹³æ»‘åŠ¨ä½œåºåˆ—çš„ä¸é”™æ–¹å¼ï¼Œä½†æ˜¯æ¨ç†é€Ÿåº¦å’Œè®¡ç®—æˆæœ¬åº”è¯¥æ˜¯æœ‰å±€é™æ€§çš„;ï¼ˆè¿™ç¯‡æ–‡ç« çœ‹äº†è›®ä¹…...ï¼‰ï¼Œä»£ç ä¹Ÿéœ€è¦è®¤çœŸè§£è¯»ä¸€ä¸‹|
|Supervised Policy Learning for Real Robots|RSS 2024 Tutorial|Start Simple.|1âœ…,2âŒ›ï¸,3âŒ›ï¸,4âœ…|
|Hierachical Diffusion Policy: manipulation trajectory generation via contact guidance|arxiv|æ–‡ç« æå‡ºäº†ä¸€ä¸ªåˆ†å±‚æ‰©æ’’ç­–ç•¥ï¼Œä¸€å…±ä¸¤ä¸ªå±‚æ¬¡ï¼šé«˜å±‚è´Ÿè´£æ¥è§¦è§„åˆ’ï¼Œåº•å±‚è´Ÿè´£è½¨è¿¹ç”Ÿæˆ;æŒ‰ç…§è¿™ä¸ªæ€æƒ³ï¼Œæ–‡ç« è®¾è®¡äº†ä¸‰ä¸ªæ¨¡å—ï¼Œåˆ†åˆ«ä¸ºGuiderï¼ŒCriticå’ŒActorï¼Œå‰ä¸¤ä¸ªåˆ†åˆ«è´Ÿè´£æä¾›robotæ¥è§¦ä½ç½®å’Œåˆ¤æ–­å½“å‰åŠ¨ä½œåºåˆ—çš„Qå€¼ï¼ŒåŠ¨ä½œæ‰§è¡Œæ¨¡å‹åˆ™è´Ÿè´£ç”ŸæˆTæ—¶é—´æ®µå†…çš„åŠ¨ä½œåºåˆ—å¹¶ä¼ é€’ç»™Criticï¼Œç”±Crticç­›é€‰å‡ºçŸ­æœŸæ­¥é•¿å†…çš„åŠ¨ä½œæ‰§è¡ŒåŠ¨ä½œï¼Œä»è€Œé¿å…â€œå¾ˆä¹…ä»¥å‰çš„åŠ¨ä½œâ€å¯¹åç»­åŠ¨ä½œäº§ç”Ÿçš„å½±å“ï¼›å¯¹äºæ•°æ®å¤„ç†ï¼Œæ–‡ç« å°†æ„ŸçŸ¥è¾“å…¥ç¼–ç ä¸ºç‚¹äº‘å½¢å¼ï¼Œä½œä¸ºrobotå½“å‰çš„çŠ¶æ€è¾“å…¥ã€‚|é€æ­¥train three networksæ˜¯ä¸æ˜¯æœ‰ç‚¹éš¾é¡¶ï¼›æ–‡ç« åœ¨è®¾è®¡ç›®æ ‡ç‰©æ¥è§¦ä½ç½®/è·¯çº¿çš„æ—¶å€™ä½¿ç”¨äººå·¥æ ‡å®šçš„æ–¹å¼ä½œä¸ºprompt|
|VQ-BeT: Behavior generation with latent actions|ICML2024(SOTA)|æ–‡ç« é’ˆå¯¹Behavior Transformerï¼ˆBeTï¼‰å…³äºkå€¼é€‰å–å’Œå¯¹é«˜ç»´æˆ–é•¿åºåˆ—æ‰€å¯¼è‡´çš„æ¢¯åº¦ç¼ºå¤±é—®é¢˜ï¼Œåœ¨ç¬¬ä¸€é˜¶æ®µæ²¿ç”¨äº†VQ-VAEä¸­çš„é‡åŒ–å‘é‡ç¼–ç -è§£ç æ€æƒ³ï¼Œå®ŒæˆåŠ¨ä½œåºåˆ—ç¼–ç -è§£ç çš„ä»»åŠ¡ï¼›æ­¤å¤–ï¼Œåœ¨ç¬¬äºŒé˜¶æ®µå¼•å…¥äº†MiniGPTæ¥è¿›è¡Œç¼–ç é¢„æµ‹ï¼ˆCode Prediction headï¼‰å’Œåç¦»çº æ­£ï¼ˆOffset headï¼‰ï¼Œæ¥å¸®åŠ©é‡æ„é‡‡æ ·åŠ¨ä½œåºåˆ—ã€‚VQ-BeTåœ¨å®éªŒæ•ˆæœå’Œæ‰§è¡Œæ•ˆç‡ä¸Šéƒ½æœ‰ç€ä¸é”™çš„è¡¨ç°ã€‚|åœ¨å®éªŒéƒ¨åˆ†ï¼Œä¸ºä»€ä¹ˆGoal-Conditional behavior generationæ•ˆæœè¿˜è¦æ›´å·®ä¸€äº›å‘¢ï¼Ÿåè€Œæ˜¯Unconditional behavior generationçš„æ•ˆæœåœ¨ 5 of 6 tasksè¡¨ç°çš„éƒ½å¾ˆå¥½ã€‚æ–‡ç« ä¸­æœªç»™å‡ºæ¨¡å‹å‚æ•°é‡çš„æ¯”è¾ƒï¼Œä½†æ˜¯å¯ä»¥æ¨æµ‹åˆ°ï¼šVQ-BeTçš„å‚æ•°é‡åº”è¯¥æ˜¯ï¼ˆè¿œï¼‰å¤§äºDiffusion Policyç­‰ç®—æ³•çš„ï¼Œç©ºé—´æ¢æ—¶é—´çš„ç»å…¸æ“ä½œ|
|RVT-2: Learning precise manipulation from few demonstrations|RSS2024|æ–‡ç« ç›¸æ¯”äºRVTä¸»è¦è¡¨ç°åœ¨å¯ä»¥å®Œæˆé«˜ç²¾åº¦ä»»åŠ¡ä»¥åŠæå‡äº†æ¨æ–­å’Œæ‰§è¡Œæ•ˆç‡ï¼Œæ¨¡å‹é‡‡ç”¨äº†å¤šé˜¶æ®µè®¾è®¡ï¼Œç¬¬ä¸€å±‚å°†è¾“å…¥RGB-Då›¾åƒé‡æ„ä¸ºç‚¹äº‘åï¼Œç”±å¤šè§†è§’Transformerç²—ç•¥å®Œæˆçƒ­åŠ›ç‚¹çš„é¢„æµ‹ï¼ˆå¤¹çˆªçš„è§¦ç‚¹ï¼‰ï¼›åœ¨ç¬¬äºŒé˜¶æ®µï¼Œç”±ä¸‰ä¸ªè™šæ‹Ÿæœºä½æ”¾å¤§é¢„æµ‹ä½ç½®4å€ï¼Œå†äº¤ç”±å¤šè§†è§’Transformerè¿›è¡Œç»†ç²’åº¦çƒ­åŠ›ç‚¹é¢„æµ‹ï¼Œè¾“å‡ºç»™æœºæ¢°è‡‚å®ŒæˆæŠ“å–å·¥ä½œï¼ˆMVTæä¾›æŠ“å–ä½ç½®ï¼Œçƒ­åŠ›ç‚¹çš„å›¾åƒè¾“å…¥MLPåå¾—åˆ°å¤¹çˆªæ–¹å‘ï¼Œå¼€å…³å’Œæ˜¯å¦ç¢°æ’ç­‰ä¿¡æ¯ï¼‰|RVT2å°†RVTä¸­çš„5ä¸ªè™šæ‹Ÿæ‘„åƒæœºä½å‡å°‘åˆ°äº†3ä¸ªï¼Œæ­¤å¤–æ‰‹æ“äº†æ–°çš„ç‚¹äº‘æ¸²æŸ“è¡¥ä¸å¹¶åŸºäºGPUåŠ é€Ÿæ–¹å¼è°ƒæ•´äº†åƒç´ ç‚¹ç´¢å¼•å€¼å’Œæ·±åº¦å€¼çš„ç²¾åº¦ï¼Œä¹Ÿç®—æ˜¯é’ˆå¯¹æ‰§è¡Œæ•ˆç‡æå‡åšäº†é’ˆå¯¹æ€§çš„å·¥ä½œğŸ«¡|
|Instant Policy: In-Context Imitation Learning via Graph Diffusion|ICLR2025|ä½œè€…ä»¥å›¾ç¥ç»ä¸ºç»“æ„ï¼Œå¯ä»¥ç®€å•çš„ç†è§£ä¸ºGNN+Diffusion Policyï¼Œå¯¹äºå¾—åˆ°æ¯ä¸ªèŠ‚ç‚¹çš„ç‰¹å¾éƒ¨åˆ†ï¼ˆä¸åŒçš„èŠ‚ç‚¹ä½œç”¨æ˜¯ä¸åŒçš„ï¼Œåˆ†åˆ«ä»£è¡¨ç€åŠ¨ä½œï¼Œæœºå™¨äººçŠ¶æ€->åŸºæœ¬å°±æ˜¯å¤¹çˆªçš„å¼€å…³çŠ¶æ€ï¼Œç›®æ ‡ç‰©çš„ä¿¡æ¯ï¼‰ï¼Œéƒ½è¦å…ˆèåˆä¸Šä¸€ä¸ªèŠ‚ç‚¹çš„ç‰¹å¾ï¼Œç„¶åå†è¿›è¡ŒKï¼ˆåŠ å™ªå£°ï¼‰+Kï¼ˆå»å™ªå£°ï¼‰æ­¥çš„æ‰©æ•£ç”Ÿæˆï¼Œæœ€åæ³¨æ„åŠ›èåˆå‘¨å›´edgeå’Œé‚»èŠ‚ç‚¹ç‰¹å¾ä¿¡æ¯åˆ°å½“å‰èŠ‚ç‚¹ï¼›åœ¨æµ‹è¯•è¿‡ç¨‹ä¸­ï¼Œå¯¹å…¶é¢„æµ‹å¤¹çˆªçŠ¶æ€ï¼ˆå¼€/å…³ï¼‰ä¸Ground Turthï¼Œåˆå¼•å…¥äº†SVDæŸå¤±ä¸ºæ¨¡å‹æ‰§è¡ŒåŠ¨ä½œæ—¶åŠ ä¸€å±‚ä¿éšœ|å…ˆè¯´è¿™ä¸ªæ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹...è¿™ä¸ªè¿‡ç¨‹...æŒºå¥½ğŸ™‚...å¯èƒ½è¿™æ ·çš„æ“ä½œæ‰ä¿è¯äº†æ¯ä¸ªèŠ‚ç‚¹ç‰¹å¾ä¿¡æ¯ä¸°å¯Œä»¥åŠæ¨¡å‹çš„zero-shot transferï¼Œ(å½“å¤ä¹ Graph Neural NetworksğŸ¥±)ï¼›ç”¨å›¾ç¥ç»ç½‘ç»œå»è§£é‡Šä¸Šä¸‹æ–‡å­¦ä¹ æ˜¯æœ‰è¯´æœåŠ›çš„ï¼Œæ¯•ç«Ÿå›¾ç½‘ç»œçš„ç»“æ„ä¼˜åŠ¿åœ¨é‚£é‡Œæ‘†ç€|
|RLBench: The Robot Learning Benchmark & Learning Environment|ICRA2020 & RA-L2020|æä¾›äº†ä¸€ä¸ªæ ‡å‡†çš„robotic learning benchmarkï¼ŒåŒ…æ‹¬å¼ºåŒ–å­¦ä¹ ï¼Œæ¨¡ä»¿å­¦ä¹ å’Œå…ƒå­¦ä¹ |ç›´æ¥ä¸Šæ‰‹æï¼Œåˆ«åºŸè¯ğŸ˜¾|
|Open X-Embodiment: Robotic Learning Datasets and RT-X Models|arxiv2023-dataset|è¿™ç¯‡æ–‡ç« ä¼šä¸ä¼šæˆä¸ºæœªæ¥æœ€å¤§è§„æ¨¡çš„å¤šä»»åŠ¡ï¼Œå¤šæœºå™¨äººçš„å­¦ä¹ æ•°æ®é›†æˆ‘ä¸ç¡®å®šï¼Ÿä½†åº”è¯¥ä¼šæ˜¯è®¡ç®—æœºä¸Šåˆä½œè€…æœ€ä¼—å¤šçš„ä¸€æ¬¡ã€‚|å¼•ç”¨å¼ å·è€å¸ˆåœ¨è¯¾å ‚ä¸Šçš„ä¸€å¥è¯â€œæœªæ¥çš„è¶‹åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿæ˜¯å¼€æºï¼Œæ˜¯æ´¾æ£®â€ğŸ¤£|
|Safe Controller Optimization for Quadrotors with Gaussian Processes|ICRA2016-Controller|æ–‡ç« æ˜¯é€šè¿‡æ•°æ®é©±åŠ¨çš„æ–¹å¼(GP + SafeOpt)æ¥ä¼˜åŒ–æ§åˆ¶å™¨å‚æ•°ï¼Œåœ¨ä¿éšœå®‰å…¨çš„å‰æä¸‹æå‡æ§åˆ¶å™¨çš„ç¨³å®šæ€§ï¼Œé€‚åº”å®æ—¶çš„ç¯å¢ƒå˜åŒ–|æ„Ÿè§‰å¦‚ä½•åˆå§‹åŒ–Safe Set åº”è¯¥æ˜¯éå¸¸é‡è¦çš„â€¼ï¸|
|DroneDiffusion: Robust Quadrotor Dynamics Learning with Diffusion Models|ICRA2025-Dynamics Learning|ä½œè€…ä½¿ç”¨æ¡ä»¶æ‰©æ•£æ¨¡å‹æ¥æ•æ‰ç¯å¢ƒä¸­çš„å¤šæ¨¡æ€å¹²æ‰°ï¼ˆç¡®å®šæ€§å¹²æ‰°å¦‚é£é€Ÿï¼Œè´Ÿè½½ç­‰ï¼Œä¸ç¡®å®šæ€§å¹²æ‰°å¦‚æœªçŸ¥éšœç¢ç‰©ï¼Œç¯å¢ƒçªç„¶å˜åŒ–ç­‰ï¼‰ï¼Œå¹¶å¼•å…¥æ»‘æ¨¡å˜é‡æ„å»ºæ··åˆæ§åˆ¶å™¨ï¼Œèåˆé¢„æµ‹ä¸å®æ—¶åº”å˜èƒ½åŠ›ï¼Œå¸®åŠ©æ— äººæœºåœ¨å¤šå˜çš„ç¯å¢ƒä¸­ä¿æŒé£è¡Œå’Œè´Ÿè½½ç¨³å®šï¼›æ‰©æ•£æ¨¡å‹ä»¥ä¼ æ„Ÿå™¨æ•°æ®ï¼ˆä½ç½®ï¼Œé€Ÿåº¦ï¼‰å’Œæ§åˆ¶è¾“å…¥ä¸ºinputï¼Œè®­ç»ƒæ‹Ÿåˆå¤šæ¨¡æ€æ®‹å·® $\mathcal{H}$|é¦–å…ˆè¿™ä¸ªæ¨¡å‹å¼ºä¾èµ–äºä¼ æ„Ÿå™¨æ•°æ®ï¼Œå¦‚æœä¼ æ„Ÿå™¨ä¸èƒ½åŠæ—¶è·å–å‡†ç¡®æœ‰æ•ˆçš„å‚æ•°ï¼ŒDMé¢„æµ‹å€¼åº”è¯¥ä¼šæœ‰è¾ƒå¤§åå·®ï¼›å…¶æ¬¡ï¼ŒDMæ¨¡å‹çš„è®¡ç®—æˆæœ¬é—®é¢˜ï¼Œå°†ä¼šç»™å®é™…éƒ¨ç½²å¸¦æ¥ä¸»è¦çš„çº¦æŸğŸ§¶|
|Safe Bayesian Optimization for the Control of High-Dimensional Embodied Systems|CoRL2024-Controller & Bayesian|é’ˆå¯¹é«˜çº¬é‡‡æ ·å’Œä¼˜åŒ–é—®é¢˜ï¼Œï¼›ç­‰è·åµŒå…¥ï¼›||

## Waiting List
|TitleğŸ“–    |YearğŸ§“ |StatusğŸª£  |
|:---------|:---------|:---------|
|RLBench: The Robot Learning Benchmark & Learning Environment|ICRA2020|âŒ›ï¸Robo Benchmark(Next One...)â¡ï¸03.07âœ…|
|Rvt-2: Learning precise manipulation from few demonstrations|RSS2024|ğŸ™Manipulationâ¡ï¸03.05âœ…|
|3d gaussian splatting for real-time radiance field rendering|2023|ğŸ™Generation|
|Robodreamer: Learning compositional world models for robot imagination|2024|ğŸ™World Model|
|Instant Policy: In-Context Imitation Learning via Graph Diffusion|ICLR2025 Oral|âŒ›ï¸Imitation Learningâ¡ï¸03.07âœ…|
|Open X-Embodiment: Robotic Learning Datasets and RT-X Models|Dataset2023|âŒ›Multi-Task Multi-Robot Datasetsâ¡ï¸03.07âœ…|
|VQ-BeT: Behavior generation with latent actions|ICML2024|âŒ›ï¸Policy Leaningâ¡ï¸03.05âœ…|
|UMI: Universal Manipulation Interface: In-The-Wild Robot Teaching Without In-The-Wild Robots|RSS2024|âŒ›ï¸Data Collection|
|ALOHA: Learning Fine Grained Bimanual Manipulation with Low-Cost Hardware|RSS2023|âŒ›ï¸Policy Learning & Data Collecyion|
|Humanoid Locamotion as Next PredictionğŸŒŸ|NIPS2024 Spotlight|âŒ›ï¸humanoid Contorl|
|Safe Bayesian Optimization for the Control of High-Dimensional Embodied Systems|CoRL2024|âŒ›ï¸Controller & Bayesian|
|On safety in safe bayesian optimization|TMLR2024|âŒ›ï¸Bayesian Optimization|
|Adaptive and safe bayesian optimization in high dimensions via one-dimensional subspace|ICML2019|âŒ›ï¸Bayesian Optimization|
|Meta-learning priors for safe bayesian optimization|CoRL2022|âŒ›ï¸Bayesian Optimization|
|Relaxing the additivity constraints in decentralized no-regret high-dimensional bayesian optimization|ICLR2024|âŒ›ï¸Bayesian Optimization|
|RL-based adaptive controller for high precision reaching in a soft robot arm|T-RO2024|âŒ›ï¸Controller|

## ROSğŸ¤–
I am learning about Robot Operating System(ROS) from [AJie](https://www.bilibili.com/video/BV1BP4y1o7pw) on Bilibili website.

Completion: 10/77 âŒ›ï¸

## SimulatorğŸ’»
Considering the complexity of differnt simulators, choose [MUJOCO](https://github.com/google-deepmind/mujoco) as the first step to help me train/test robot(Galaxea A1 and Franka Research 3). Maybe, [Nvidia Issac Sim for C++/Python](https://docs.isaacsim.omniverse.nvidia.com/4.5.0/introduction/quickstart_index.html) and [Drake for C++/Python](https://drake.mit.edu/) are also good choice. Besides, we can learn about introduction and basic knowledge about MUJOCO from [Prof.Wei Zhang, SUSTech](https://www.bilibili.com/video/BV1wPyfYHEmE).

## Machine Learning & Deep Learning ğŸ°
Personally thinking, [Prof.Hung-Yi Lee's ML courses](https://speech.ee.ntu.edu.tw/~hylee/ml/2016-fall.php) are the most outstanding around all of Internet coursesâœŠ. There are many interesting PokÃ©mon examplesğŸ˜ (Now if you are in China Mainland, maybe scientic surfing is all you need.ğŸ›) To Deep Learning, recommand to read *[Deep Learning, written by Ian Goodfellow and Yoshua Bengio and Aaron Courville, MIT Press](https://www.deeplearningbook.org/front_matter.pdf)*, called "èŠ±ä¹¦" in Chinese and practice code skills following *[Deep Learning with Pytorch, written by Eli Stevens and Luca Antiga and Thomas Viehmann](https://isip.piconepress.com/courses/temple/ece_4822/resources/books/Deep-Learning-with-PyTorch.pdf)*.
